# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WajmjKr8xz9tKagBfmW2mHg02DJSV0zP
"""

import streamlit as st
import torch
from torchvision import transforms
from PIL import Image
import torch.nn as nn
from torchvision import models

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
@st.cache_resource
def load_model():
    model = models.resnet18(pretrained=False)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 2)
    model.load_state_dict(torch.load("xray_model.pth", map_location="cpu"))
    model.eval()
    return model

model = load_model()

# ØªÙ‡ÙŠØ¦Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.title("ğŸ©º ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø£Ø´Ø¹Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

# Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
uploaded_file = st.file_uploader("Ø­Ù…Ù‘Ù„ ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø© (X-Ray)", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø©", use_container_width=True)

    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"):
        img_tensor = transform(image).unsqueeze(0)
        with torch.no_grad():
            outputs = model(img_tensor)
            _, predicted = torch.max(outputs, 1)

        if predicted.item() == 0:
            st.success("âœ… Ø§Ù„ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© (Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø±Ø¶)")
        else:
            st.error("âš ï¸ Ø§Ø­ØªÙ…Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø£Ø´Ø¹Ø©")

st.markdown("---")
st.caption("ğŸ“˜ ØªØ·Ø¨ÙŠÙ‚ ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch Ùˆ Streamlit")